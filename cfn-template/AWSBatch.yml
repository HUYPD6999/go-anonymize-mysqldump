AWSTemplateFormatVersion: '2010-09-09'
Description: AWS Batch
Parameters:
  ECRBatchRepoName:
    Type: String
    Default: mysql-masked-db-repo
    Description: "ECR Repo Store Batch Image"
  PrivateSubnet1:
    Description: "Enter the ID of the first subnet"
    Type: AWS::EC2::Subnet::Id
  PrivateSubnet2:
    Description: "Enter the ID of the second subnet"
    Type: AWS::EC2::Subnet::Id
  PrivateSubnet3:
    Description: "Enter the ID of the second subnet"
    Type: AWS::EC2::Subnet::Id     
  BatchComputeEnvironmentName:
    Type: String
    Default: mysql-maskdb-compute-env
    Description: "AWS Batch Compute Environment Name"
  JobDefinitionName:
    Type: String
    Default: mysql-maskdb-job-definition
    Description: "AWS Batch Job Definition Name"
  JobQueueName:
    Type: String
    Default: mysql-maskdb-jobqueue
    Description: "AWS Batch Job Queue Name"
  S3Target:
    Type: String
    Default: mysql-maskdb-bucket
    Description: "s3 bucket store masked mysql dump"    
  LambdaFunctionName:
    Type: String
    Default: mysql-maskdb-function
    Description: "Lambda Name"                   
  VPCID:
    Description: "Enter the ID of VPC"
    Type: AWS::EC2::VPC::Id
Resources:
  S3Bucket:
    Type: 'AWS::S3::Bucket'
    DeletionPolicy: Retain
    Properties:
      BucketName: !Ref S3Target
  ExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ecs.amazonaws.com
                - ecs-tasks.amazonaws.com
            Action: ['sts:AssumeRole']
      Path: /
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess'
        - 'arn:aws:iam::aws:policy/CloudWatchFullAccess'
        - 'arn:aws:iam::aws:policy/AmazonS3FullAccess'
  EcrRepository:
    Type: AWS::ECR::Repository
    Properties:
      RepositoryName: !Ref ECRBatchRepoName
      RepositoryPolicyText:
        Version: 2012-10-17
        Statement:
          - Sid: ecr-repo-statement
            Effect: Allow
            Principal:
              AWS: !Ref 'AWS::AccountId'
            Action:
              - 'ecr:*'
      LifecyclePolicy:
        LifecyclePolicyText: !Sub |
          {
            "rules": [
              {
                "rulePriority": 10,
                "description": "Policy for any images",
                "selection": {
                  "tagStatus": "any",
                  "countType": "imageCountMoreThan",
                  "countNumber": 5
                },
                "action": {
                  "type": "expire" 
                }
              }
            ]
          }
  ContainerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Access to the Fargate containers
      VpcId: !Ref VPCID
  FargateContainerSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupName: "BatchFargateSecurityGroup"
      GroupDescription: 'Security group for BatchFargate'
      VpcId: !Ref VPCID
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          SourceSecurityGroupId: !Ref ContainerSecurityGroup          
  ComputeEnvironment:
    Type: "AWS::Batch::ComputeEnvironment"
    Properties:
      Type: "MANAGED"
      ServiceRole: !Sub "arn:aws:iam::${AWS::AccountId}:role/service-role/AWSBatchServiceRole"
      ComputeEnvironmentName: !Ref BatchComputeEnvironmentName
      ComputeResources:
        MaxvCpus: 8
        SecurityGroupIds:
          - !Ref FargateContainerSecurityGroup
        Type: "FARGATE"
        Subnets:
          - !Ref PrivateSubnet1
          - !Ref PrivateSubnet2
          - !Ref PrivateSubnet3      
      # State: "ENABLED"
  JobQueue:
    DependsOn: ComputeEnvironment
    Type: "AWS::Batch::JobQueue"
    Properties:
      ComputeEnvironmentOrder:
        - Order: 1
          ComputeEnvironment: !Ref ComputeEnvironment
      State: "ENABLED"
      Priority: 1
      JobQueueName: !Ref JobQueueName
  Job:
    Type: "AWS::Batch::JobDefinition"
    Properties:
      Type: "container"
      JobDefinitionName: !Ref JobDefinitionName
      Timeout: 
        AttemptDurationSeconds: 1200
      PlatformCapabilities:
        - FARGATE
      ContainerProperties: 
        ResourceRequirements:
          - Type: VCPU
            Value: 1
          - Type: MEMORY
            Value: 2048         
        Image: !GetAtt EcrRepository.RepositoryUri
        NetworkConfiguration:
          AssignPublicIp: ENABLED
        ExecutionRoleArn: !GetAtt ExecutionRole.Arn
        JobRoleArn: !GetAtt ExecutionRole.Arn
        FargatePlatformConfiguration:
          PlatformVersion: LATEST
      RetryStrategy: 
        Attempts: 1 
  LambdaRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: maskdb-lambda-role
      AssumeRolePolicyDocument:
        Statement:
          - Action:
            - sts:AssumeRole
            Effect: Allow
            Principal:
              Service:
              - lambda.amazonaws.com
        Version: 2012-10-17
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AWSLambdaExecute
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AWSBatchFullAccess
      Path: /
  LambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Ref LambdaFunctionName
      Description: Lambda function call AWS Batch
      Handler: index.lambda_handler
      Runtime: python3.7
      Code:
        ZipFile: |
          import json
          import urllib.parse
          import boto3
          import os

          print('Loading function')

          s3 = boto3.client('s3')
          batch = boto3.client('batch')

          def lambda_handler(event, context):
              bucket = event['Records'][0]['s3']['bucket']['name']
              key = event['Records'][0]['s3']['object']['key']

              try:
                  response = batch.submit_job(
                      jobDefinition = os.environ['JOB_DEFINITION'],
                      jobName = os.environ['JOB_NAME'],
                      jobQueue = os.environ['JOB_QUEUE'],
                      containerOverrides={
                          'environment': [
                              {
                                  'name': 'S3_BUCKET_SOURCE',
                                  'value': bucket
                              },
                              {
                                  'name': 'S3_OBJ',
                                  'value': key
                              },
                              {
                                  'name': 'S3_BUCKET_TARGET',
                                  'value': os.environ['S3_BUCKET_TARGET']
                              }                    
                          ]
                      }            
                  )
                  print(response)
              except Exception as e:
                  print(e)
                  print('Error')
                  raise e
      Handler: lambda_function.lambda_handler
      MemorySize: 128
      Timeout: 15
      Role:
        Fn::GetAtt:
          - LambdaRole
          - Arn
      Environment:
        Variables:
          JOB_DEFINITION: !Ref JobDefinitionName
          JOB_NAME: mysql-mask-db
          JOB_QUEUE: !Ref JobQueueName
          S3_BUCKET_TARGET: !Ref S3Bucket
Outputs:
  ECRRepoURI:
    Description: ECR Repo URI
    Value: !GetAtt EcrRepository.RepositoryUri
